{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64fe4451",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fralfaro/MAT281_2023/blob/main/docs/labs/lab_032.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# MAT281 - Laboratorio N°03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a15921",
   "metadata": {},
   "source": [
    "Esta semana revisaremos datos del **Índice de Libertad de Prensa** que confecciona cada año la asociación de Reporteros Sin Fronteras.\n",
    "\n",
    "> **Nota**: el conjunto a utilizar lo encuentra en el siguiente [link](https://drive.google.com/drive/folders/1zxiYb5ji_xa5_5tWxvdjCEGYRY9YvjR7?usp=drive_link).\n",
    "\n",
    "## Diccionario de datos\n",
    "\n",
    "\n",
    "|Variable       |Clase               |Descripción |\n",
    "|:--------------|:-------------------|:-----------|\n",
    "| codigo_iso | caracter | Código ISO del país |\n",
    "| pais | caracter | País |\n",
    "| anio | entero | Año del resultado |\n",
    "| indice | entero | Puntaje Índice Libertad de Prensa (menor puntaje = mayor libertad de prensa) |\n",
    "| ranking | entero | Ranking Libertad de Prensa |\n",
    "\n",
    "\n",
    "## Fuente original y adaptación\n",
    "Los datos fueron extraídos de [The World Bank](https://tcdata360.worldbank.org/indicators/h3f86901f?country=BRA&indicator=32416&viz=line_chart&years=2001,2019). La fuente original es [Reporteros sin Fronteras](https://www.rsf-es.org/). \n",
    "\n",
    "Por otro lado, estos archivos han sido modificado intencionalmente para ocupar todo lo aprendido en clases. A continuación, una breve descripción de cada uno de los data frames:\n",
    "\n",
    "* **libertad_prensa_codigo.csv**: contiene la información codigo_iso/pais. Existe un código que tiene dos valores.\n",
    "* **libertad_prensa_anio.csv**: contiene la información pais/anio/indice/ranking. Los nombres de las columnas estan en mayúscula.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed417506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6088c5c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9712\\1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28a58320",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: '/content/drive/my-drive/data_sets/libertad_prensa/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9712\\3682831980.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/content/drive/my-drive/data_sets/libertad_prensa/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0marchivos_anio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'libertad_prensa_codigo'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_codigos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'libertad_prensa_codigo.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: '/content/drive/my-drive/data_sets/libertad_prensa/'"
     ]
    }
   ],
   "source": [
    "path = \"/content/drive/my-drive/data_sets/libertad_prensa/\" \n",
    "\n",
    "archivos_anio = [path + f for f in listdir(path) if 'libertad_prensa_codigo' not in f ] \n",
    "df_codigos = pd.read_csv(path + 'libertad_prensa_codigo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0894056d",
   "metadata": {},
   "source": [
    " El objetivo es tratar de obtener la mayor información posible de este conjunto de datos. Para cumplir este objetivo debe resolver las siguientes problemáticas:\n",
    " \n",
    "1. Lo primero será juntar toda la información en un _solo archivo_, para ello necesitamos seguir los siguientes pasos:\n",
    "\n",
    " * a) Crear el archivo **df_anio**, que contenga la información de **libertad_prensa_anio.csv** para cada año. Luego, normalice el nombre de las columnas a minúscula.\n",
    " * b) Encuentre y elimine el dato que esta duplicado en el archivo **df_codigo**.\n",
    " * c) Crear el archivo **df** que junte la información del archivo **df_anio** con **df_codigo** por la columna _codigo_iso_.\n",
    " \n",
    "> **Hint**: Para juntar por _anio_ ocupe la función **pd.concat**. Para juntar información por columna ocupe **pd.merge**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfd268a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\nico6\\\\OneDrive\\\\Escritorio\\\\data\\\\datalibertad_prensa_2001.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9712\\1811683609.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Se crea una lista vacía para llenarla con los dataframes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0march\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marchivos_anio\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0march\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Se lee cada archivo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mlista\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_temp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Se agregan a la lista\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_anio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Se juntan todas las listas para hacer una lista de listas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\nico6\\\\OneDrive\\\\Escritorio\\\\data\\\\datalibertad_prensa_2001.csv'"
     ]
    }
   ],
   "source": [
    "#1a) Solucion\n",
    "\n",
    "list = [] #Se crea una lista vacía para llenarla con los dataframes\n",
    "for arch in archivos_anio:\n",
    "    df_temp = pd.read_csv(arch) #Se lee cada archivo\n",
    "    lista.append(df_temp) #Se agregan a la lista\n",
    "df_anio = pd.concat(list) #Se juntan todas las listas para hacer una lista de listas\n",
    "df_anio.columns = df_anio.columns.str.lower() #Se cambia el nombre de las columnas a minusculas\n",
    "df_anio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6333e84f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_codigos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9712\\396615783.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#1b) Solucion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_codigos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'codigo_iso'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Se cuentan los valores duplicados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_codigos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_codigos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_codigos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pais'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'malo'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Se elimina el duplicado\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_codigos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_codigos' is not defined"
     ]
    }
   ],
   "source": [
    "#1b) Solucion\n",
    "\n",
    "df_codigos['codigo_iso'].value_counts() #Se cuentan los valores duplicados\n",
    "df_codigos = df_codigos[df_codigos['pais']!='malo'] #Se elimina el duplicado\n",
    "df_codigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b58b91e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_anio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9712\\961060856.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#1c) Solucion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_anio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_codigos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'codigo_iso'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Se usa merge para juntar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_anio' is not defined"
     ]
    }
   ],
   "source": [
    "#1c) Solucion\n",
    "\n",
    "df = pd.merge(df_anio,df_codigos,on='codigo_iso') #Se usa merge para juntar\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282e8301",
   "metadata": {},
   "source": [
    "2. Encontrar:\n",
    "   * ¿Cuál es el número de observaciones en el conjunto de datos?   \n",
    "   * ¿Cuál es el número de columnas en el conjunto de datos?   \n",
    "   * Imprime el nombre de todas las columnas  \n",
    "   * ¿Cuál es el tipo de datos de cada columna? \n",
    "   * Describir el conjunto de datos (**hint**: .describe())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14369830",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9712\\844460234.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#a) #Cantidad de observaciones:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcant_fil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Se ve la cantidad de filas que tiene el df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"El numero de observaciones es: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcant_fil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Solucion\n",
    "\n",
    "#a) #Cantidad de observaciones:\n",
    "\n",
    "cant_fil = df.shape[0] #Se ve la cantidad de filas que tiene el df\n",
    "print(\"El numero de observaciones es: \", cant_fil)\n",
    "print(\"\") \n",
    "\n",
    "#b) #Numero de columnas\n",
    "\n",
    "cant_col = df.shape[1] #Se ve la cantidad de columnas que tiene el df\n",
    "print(\"El numero de columnas es: \", cant_col)\n",
    "print(\"\")\n",
    "\n",
    "#c) #Imprimir el nombre de todas las columnas\n",
    "\n",
    "print(\"El nombre de las columnas son:\")\n",
    "aux = df.columns.tolist() #Se crea una lista con todos los elementos\n",
    "for j in range(len(aux)):\n",
    "  print(aux[j])\n",
    "print(\"\")\n",
    "\n",
    "#d) #Tipo de datos de cada columna\n",
    "\n",
    "print(\"El tipo de dato de cada columna es:\")\n",
    "print(df.dtypes) \n",
    "print(\"\")\n",
    "\n",
    "#e) #Descripción del conjunto de datos\n",
    "\n",
    "print(\"El conjunto de datos descritos:\")\n",
    "print(df.describe(include='all')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebfbbea",
   "metadata": {},
   "source": [
    "3. Desarrolle una función `resumen_df(df)` para encontrar el total de elementos distintos y vacíos por columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b571f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solucion\n",
    "\n",
    "def resumen_df(df):\n",
    "    nombres = df.columns\n",
    "\n",
    "    unique_list = [] \n",
    "    null_list = [] \n",
    "    \n",
    "    for j in nombres:               \n",
    "      unique = (len(df[j].unique())) #Se usa \"unique\" para ver los elementos que son nulos, por cada columna, y len para contar\n",
    "      empty = (df[j].isnull().sum()) #Lo mismo de antes con \"isnull\"\n",
    "      \n",
    "      if empty!=0:      \n",
    "         unique = unique - 1; \n",
    "        \n",
    "#la condición de antes es necesaria, porque la función unique() cuenta los elementos nulos como un elemento único, pero nosotros     \n",
    "#no queremos contar este elemento, pues no aporta información útil, por lo que, si la cantidad de elementos vacíos es\n",
    "#distinta de 0, se restará a la cantidad de elementos únicos.\n",
    "\n",
    "      unique_list.append(unique) \n",
    "      null_list.append(empty) \n",
    "  \n",
    "    result = pd.DataFrame({'nombres': nombres})\n",
    "    result['elementos_distintos'] = unique_list #Se pone cada componente de \"unique_list\" en su correspondiente del df result\n",
    "    result['elementos_vacios'] = null_list #Se pone cada componente de \"null_list\" en su correspondiente del df result\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ceaaaa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9712\\2526200391.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# retornar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresumen_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# retornar \n",
    "resumen_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98efcc39",
   "metadata": {},
   "source": [
    "4. Para los paises latinoamericano, encuentre por año  el país con mayor y menor `indice`.\n",
    "\n",
    " * a) Mediante un ciclo _for_.\n",
    " * b) Mediante un  _groupby_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9077a9bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9712\\3888494284.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m        'USA', 'VEN']\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf_america\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodigo_iso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamerica\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Filtra el df inicial a través del codigo iso definido en america\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#Se hará un diccionario con los países de índice menor y mayor para facilitar lectura\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Solucion\n",
    "\n",
    "america = ['ARG', 'ATG', 'BLZ', 'BOL', 'BRA', 'CAN', 'CHL', 'COL', 'CRI',\n",
    "       'CUB', 'DOM', 'ECU', 'GRD', 'GTM', 'GUY', 'HND', 'HTI', 'JAM',\n",
    "       'MEX', 'NIC', 'PAN', 'PER', 'PRY', 'SLV', 'SUR', 'TTO', 'URY',\n",
    "       'USA', 'VEN']\n",
    "\n",
    "df_america = df[df.codigo_iso.isin(america)] #Filtra el df inicial a través del codigo iso definido en america\n",
    "\n",
    "#Se hará un diccionario con los países de índice menor y mayor para facilitar lectura\n",
    "\n",
    "#a) Maximo\n",
    "\n",
    "anios = df['anio'].unique() #Se crea una lista de los años\n",
    "\n",
    "dict_mayor = dict() #Se crea un diccionario con los mayores elementos\n",
    "for k in anios:\n",
    "    df_aux = df_america.loc[lambda x: x['anio'] == k] #Se define un dataframe aux para filtrar por año\n",
    "    max_indice = df_aux['indice'].max() \n",
    "    df_aux = df_aux[df_aux['indice']==max_indice] \n",
    "    paises = list(df_aux['pais']) #Se crea una lista de elementos de la columna que tendrán el nombre de los países\n",
    "    new_paises=[] #Se crea la lista \"new_paises\", para evitar los espacios nulos y los datos que compartan indice\n",
    "    if len(paises)<1:\n",
    "      paises.append('No hay datos') \n",
    "      new_paises.append(paises[0])\n",
    "    elif len(paises)>=1:\n",
    "      new_paises.append(paises[0])\n",
    "    if (np.isnan(max_indice)==True): #Si el valor max_indice llega a ser nulo se cambia por un 0\n",
    "      max_indice = 0\n",
    "    dict_mayor[k] = [new_paises[0],max_indice] #Se crea una tupla con el nombre del país y su max_indice en el diccionario\n",
    "\n",
    "sorted(dict_mayor.items()) #Ordenamos por año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77396fd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anios' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9712\\2908326810.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdict_menor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Se crea un diccionario con los mayores elementos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manios\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mdf_aux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_america\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'anio'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Se define un dataframe aux para filtrar por año\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmin_indice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_aux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'indice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'anios' is not defined"
     ]
    }
   ],
   "source": [
    "#Solucion\n",
    "\n",
    "#a) Minimo\n",
    "\n",
    "dict_menor = dict() #Se crea un diccionario con los mayores elementos\n",
    "for k in anios:\n",
    "    df_aux = df_america.loc[lambda x: x['anio'] == k] #Se define un dataframe aux para filtrar por año\n",
    "    min_indice = df_aux['indice'].min()  \n",
    "    df_aux = df_aux[df_aux['indice']==min_indice] \n",
    "    paises = list(df_aux['pais']) #Se crea una lista de elementos de la columna que tendrán el nombre de los países\n",
    "    new_paises = [] #Se crea la lista \"new_paises\", para evitar los espacios nulos y los datos que compartan indice            \n",
    "    if len(paises)<1:\n",
    "      paises.append('No hay datos')\n",
    "      new_paises.append(paises[0])\n",
    "    elif len(paises)>=1:\n",
    "      new_paises.append(paises[0])\n",
    "    if (np.isnan(min_indice)==True): #Si el valor min_indice llega a ser nulo se cambia por un 0\n",
    "      min_indice = 0\n",
    "    dict_menor[k] = [new_paises[0],min_indice] #Se crea una tupla con el nombre del país y su min_indice en el diccionario\n",
    "\n",
    "sorted(dict_menor.items()) #Ordenamos por año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed56f37a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_america' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9712\\143964101.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#b) Maximo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmax_indice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_america\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'anio'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Se asigna a cada año el mayor indice por país\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdata_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_america\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_indice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'anio'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'_max'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Se crea un dataframe ordenado por año\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdata_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindice\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mdata_max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindice_max\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'indice_max'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'codigo_iso'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ranking'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Se sacan las columnas innecesarias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_america' is not defined"
     ]
    }
   ],
   "source": [
    "#Solucion\n",
    "\n",
    "#b) Maximo\n",
    "\n",
    "max_indice = df_america.groupby('anio').indice.max() #Se asigna a cada año el mayor indice por país\n",
    "data_max = df_america.merge(max_indice, on='anio', suffixes=('','_max')) #Se crea un dataframe ordenado por año \n",
    "data_max = data_max[data_max.indice==data_max.indice_max].drop(['indice_max','codigo_iso','ranking',], axis=1) #Se sacan las columnas innecesarias\n",
    "by_anio = data_max.sort_values('anio') #Se ordena por año\n",
    "by_anio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abafd92b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_america' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9712\\4110038970.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#b) Minimo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmin_indice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_america\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'anio'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Se asigna a cada año el menor indice por país\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdata_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_america\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_indice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'anio'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'_min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Se crea un dataframe ordenado por año\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdata_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_min\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_min\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindice\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mdata_min\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindice_min\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'indice_min'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'codigo_iso'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ranking'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Se sacan las columnas innecesarias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_america' is not defined"
     ]
    }
   ],
   "source": [
    "#Solucion\n",
    "\n",
    "#b) Minimo\n",
    "\n",
    "min_indice = df_america.groupby('anio').indice.min() #Se asigna a cada año el menor indice por país \n",
    "data_min = df_america.merge(min_indice, on='anio', suffixes=('','_min')) #Se crea un dataframe ordenado por año \n",
    "data_min = data_min[data_min.indice==data_min.indice_min].drop(['indice_min','codigo_iso','ranking',], axis=1) #Se sacan las columnas innecesarias\n",
    "by_anio = data_min.sort_values('anio') #se ordena por anio\n",
    "by_anio #Se ordena por año"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91532f43",
   "metadata": {},
   "source": [
    "5. Para cada _país_, muestre el _indice_ máximo que alcanzo por _anio_. Para los datos nulos, rellene con el valor **0**.\n",
    "\n",
    "**Ejemplo**:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ob0qch1dsOjDOUuZXnCY0HU_3XPp19gV\" width = \"700\" align=\"center\"/>\n",
    "\n",
    "> **Hint**: Utilice la función **pd.pivot_table**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c844a0a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9712\\287967411.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Solucion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'indice'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'codigo_iso'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'anio'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Solucion\n",
    "table = pd.pivot_table(df, values='indice', index=['codigo_iso'], columns=['anio'], aggfunc=np.sum, fill_value=0)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb190f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641142bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
